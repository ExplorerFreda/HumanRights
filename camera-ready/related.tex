\section{Related Work}
\label{sec:related}
%video/image geo-localization
As we have mentioned in Section~\ref{sec:introduction}, early work by Hays and Efros~\cite{hays2008im2gps} revealed the feasibility of the image localization task. % this work doesn't make sense at all. don't give too much credit to it. 
Zamir and Roshan~\cite{zamir2010accurate} used SIFT descriptors for image localization by voting, and constructed a dataset based on Google Street-View to test the efficiency of the algorithm. 
Lin et al.~\cite{lin2013cross} proposed the first ground-to-overhead geo-localization method, of which the key idea is to learn the relationship between the ground-level images and their over-head appearances. 
After that, Lin et al.~\cite{lin2015learning} then published an approach by convolutional neural network(CNN) to learn deep representations for ground-to-overhead geo-localization. 
Vo and Hays~\cite{vo2016localizing} then explored several deep CNN architectures for the cross-domain matching and improved the accuracy of image geo-localization. 
What's more, Bansal et al.~\cite{bansal2012ultra} proposed a method to capture the structure of self-similarity of patterns on facades for image geo-localization.

Leung et al.~\cite{leung2008localization} designed a monocular vision based particle filter localization system for urban settings that uses aerial reference map. 
However, because of the great similarity between the task of image localization and video localization, researchers often treat them as the same task.

Visual place recognition is a similar task of image geo-localization. 
Arandjelovic et al.~\cite{Arandjelovic16} developed NetVLAD, a CNN architecture of which the main component is the VLAD (``Vectors of Locally Aggregated Descriptors'') layer and got the state-of-the-art performance on two challenging place recognition datasets. 

While attention-based models are widely used in recognition tasks, many recent works show that attention-based model can improve the performance of machine learning models~\cite{mnih2014recurrent,zheng2015neural}. 
The key idea of attention-based model is to add attention information to build a representation. 
This idea is intuitive. 
For example, when looking at an image, we human beings often recognize the objects on it and then receive the information from the background, rather than receiving information simultaneously from the foreground objects and background scenes. 
In our approach, we compute the attention to each region by its saliency. 

% self-paced learning
In machine learning, a sequence of gradually  added training samples~\cite{bengio2009curriculum} is called a curriculum. 
Inspired by the cognitive process of humans and animals, a straightforward way to generate such a sequence is to add samples based on their ``easiness" to learn. 
However, such ``easiness" is based on specific problem and hard to generalize. 
In order to solve this problem, Self-Paced Learning (SPL) was introduced by Kumar et al.~\cite{kumar2010self}, which embeds curriculum designing into model learning. 
In SPL, the curriculum is gradually generated by the model itself based on what it has learned, and it's also a general implementation for curriculum learning. 
Following that, several works have improved self-paced learning~\cite{jiang2014easy,tang2012shifting,jiang2015self}. 
In this paper, we propose self-paced learning method to automatically estimate the saliency score for each region of a frame.

