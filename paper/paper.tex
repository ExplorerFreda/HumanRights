\documentclass[sigconf, review=true, anonymous=true]{acmart}

\usepackage{booktabs} % For formal tables
\usepackage{algorithm}
\usepackage{multirow}
\usepackage{algorithmic}
\DeclareMathOperator*{\argmax}{argmax}
\DeclareMathOperator*{\argmin}{argmin}

\begin{document}
\title{A Joint Model for Saliency Estimation and Video Localization}


\begin{abstract}
\par
In this paper, we aim to determine the location of videos by matching the frames to a reference database, which contains plenty of geo-tagged images. We have demonstrated that salient regions (e.g. buildings) of a video frame (i.e. image) contains more information than non-salient regions (e.g. sky, roads and trees), so that the saliency score can perform as a guide in the matching procedure. In consideration of this fact, we propose a joint model based on a deep CNN architecture for both estimating saliency score and optimizing the matching between images guided by the saliency score in the training procedure to solve the cross-domain image/video geo-localization problem. The experiments on Boston dataset and Tokyo 24/7 dataset have shown that our saliency aware method can help improve the accuracy of matching, and provide a reasonable explanation for the matched pairs. 
\end{abstract}

\keywords{Image Localization, Video Localization, Deep Learning}

\maketitle

\input{samplebody-conf}

\newpage
\bibliographystyle{ACM-Reference-Format}
\bibliography{sigproc} 

\end{document}
