\documentclass[sigconf, review=true, anonymous=true]{acmart}

\usepackage{booktabs} % For formal tables


% Copyright
%\setcopyright{none}
%\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
%\setcopyright{rightsretained}
%\setcopyright{usgov}
%\setcopyright{usgovmixed}
%\setcopyright{cagov}
%\setcopyright{cagovmixed}


% DOI
%\acmDOI{10.475/123_4}

% ISBN
%\acmISBN{123-4567-24-567/08/06}

%Conference
%\acmConference[ICMR'17]{ACM Woodstock conference}{July 1997}{El Paso, Texas USA} 
%\acmYear{1997}
%\copyrightyear{2016}

%\acmPrice{15.00}


\begin{document}
\title{A Joint Model for Saliency Estimation and Video Localization}

\author{Haoyue Shi}
\affiliation{
  \institution{School of Electronics Engineering and Computer Science, Peking University}
  \city{Beijing, China} 
  \postcode{100871}
}
\email{hyshi@pku.edu.cn}

\author{Jia Chen}
\affiliation{
  \institution{Language Technologies Institute, Carnegie Mellon University}
  \city{Pittsburgh, PA, USA} 
  \postcode{15213}
}
\email{jiac@cs.cmu.edu.cn}

\author{Alexander G. Hauptmann}
\affiliation{
  \institution{Language Technologies Institute, Carnegie Mellon University}
  \city{Pittsburgh, PA, USA} 
  \postcode{15213}
}
\email{alex@cs.cmu.edu.cn}

% The default list of authors is too long for headers}

\begin{abstract}
\par
In this paper, we aim to determine the location of videos by matching the frames to a reference database, which contains plenty of geo-tagged images. We have demonstrated that salient parts (e.g. buildings) of a video frame (i.e. image) contains more information than non-salient parts (e.g. sky, roads and trees), so that the saliency score can perform as a guide in the matching procedure. In consideration of this fact, we propose a joint model based on a deep CNN architecture for both estimating saliency score and optimizing the matching between images guided by the saliency score in the training procedure. The experiments on Boston dataset and Tokyo 24/7 dataset have shown that our saliency aware method can help improve the accuracy of matching, and provide a reasonable explanation for the matched pair. 
\end{abstract}

\begin{CCSXML}
<ccs2012>
 <concept>
  <concept_id>10010520.10010553.10010562</concept_id>
  <concept_desc>Computer systems organization~Embedded systems</concept_desc>
  <concept_significance>500</concept_significance>
 </concept>
 <concept>
  <concept_id>10010520.10010575.10010755</concept_id>
  <concept_desc>Computer systems organization~Redundancy</concept_desc>
  <concept_significance>300</concept_significance>
 </concept>
 <concept>
  <concept_id>10010520.10010553.10010554</concept_id>
  <concept_desc>Computer systems organization~Robotics</concept_desc>
  <concept_significance>100</concept_significance>
 </concept>
 <concept>
  <concept_id>10003033.10003083.10003095</concept_id>
  <concept_desc>Networks~Network reliability</concept_desc>
  <concept_significance>100</concept_significance>
 </concept>
</ccs2012>  
\end{CCSXML}

\ccsdesc[500]{Computer systems organization~Embedded systems}
\ccsdesc[300]{Computer systems organization~Redundancy}
\ccsdesc{Computer systems organization~Robotics}
\ccsdesc[100]{Networks~Network reliability}

% We no longer use \terms command
%\terms{Theory}

\keywords{Image Localization, Video Localization, Deep Learning}

\maketitle

\input{samplebody-conf}

\bibliographystyle{ACM-Reference-Format}
\bibliography{sigproc} 

\end{document}
